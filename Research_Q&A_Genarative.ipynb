{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgPm21CGcsNSPMeWJJ1AAm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["https://towardsdatascience.com/generative-chatbots-using-the-seq2seq-model-d411c8738ab5"],"metadata":{"id":"rkgV2mHJMzNp"}},{"cell_type":"code","execution_count":54,"metadata":{"id":"nF7hjU6nJ0uY","executionInfo":{"status":"ok","timestamp":1676605753576,"user_tz":300,"elapsed":656,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"outputs":[],"source":["import re\n","import random\n","\n","# data_path = \"human_text.txt\"\n","# data_path2 = \"robot_text.txt\"\n","\n","data_path = \"Question_new.txt\"\n","data_path2 = \"Answer_new.txt\"\n","\n","# Defining lines as a list of each line\n","with open(data_path, 'r', encoding='utf-8') as f:\n","  lines = f.read().split('\\n')\n","with open(data_path2, 'r', encoding='utf-8') as f:\n","  lines2 = f.read().split('\\n')\n","lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n","lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n","lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n","lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n","# grouping lines by response pair\n","pairs = list(zip(lines,lines2))\n","# random.shuffle(pairs)"]},{"cell_type":"code","source":["pairs[0:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3h7ZhjQKp4n","executionInfo":{"status":"ok","timestamp":1676605791542,"user_tz":300,"elapsed":132,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"723e252a-cdd9-4507-9873-3bb6f60a2bd6"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('When you go on like this you know what you sound like',\n","  'I sound like a sensible fucking man is what I sound like'),\n"," ('Can I get anybody anymore coffee', 'Oh yes thank you')]"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["import numpy as np\n","input_docs = []\n","target_docs = []\n","input_tokens = set()\n","target_tokens = set()\n","for line in pairs[:400]:\n","  input_doc, target_doc = line[0], line[1]\n","  # Appending each input sentence to input_docs\n","  input_docs.append(input_doc)\n","  # Splitting words from punctuation  \n","  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n","  # Redefine target_doc below and append it to target_docs\n","  target_doc = '<START> ' + target_doc + ' <END>'\n","  target_docs.append(target_doc)\n","  \n","  # Now we split up each sentence into words and add each unique word to our vocabulary set\n","  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n","    if token not in input_tokens:\n","      input_tokens.add(token)\n","  for token in target_doc.split():\n","    if token not in target_tokens:\n","      target_tokens.add(token)\n","input_tokens = sorted(list(input_tokens))\n","target_tokens = sorted(list(target_tokens))\n","num_encoder_tokens = len(input_tokens)\n","num_decoder_tokens = len(target_tokens)"],"metadata":{"id":"WtiI12rBJ_XT","executionInfo":{"status":"ok","timestamp":1676605802375,"user_tz":300,"elapsed":149,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["input_features_dict = dict(\n","    [(token, i) for i, token in enumerate(input_tokens)])\n","target_features_dict = dict(\n","    [(token, i) for i, token in enumerate(target_tokens)])\n","reverse_input_features_dict = dict(\n","    (i, token) for token, i in input_features_dict.items())\n","reverse_target_features_dict = dict(\n","    (i, token) for token, i in target_features_dict.items())"],"metadata":{"id":"CalTRchgMmxQ","executionInfo":{"status":"ok","timestamp":1676605805180,"user_tz":300,"elapsed":114,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["#Maximum length of sentences in input and target documents\n","max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n","max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n","encoder_input_data = np.zeros(\n","    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n","    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n","        #Assign 1. for the current line, timestep, & word in encoder_input_data\n","        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n","    \n","    for timestep, token in enumerate(target_doc.split()):\n","        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n","        if timestep > 0:\n","            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."],"metadata":{"id":"7t0vwiRLMpc-","executionInfo":{"status":"ok","timestamp":1676605805704,"user_tz":300,"elapsed":2,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","from keras.layers import Input, LSTM, Dense\n","from keras.models import Model\n","#Dimensionality\n","dimensionality = 256\n","#The batch size and number of epochs\n","batch_size = 10\n","epochs = 600\n","#Encoder\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder_lstm = LSTM(dimensionality, return_state=True)\n","encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n","encoder_states = [state_hidden, state_cell]\n","#Decoder\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n","decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"metadata":{"id":"J8dfPuQJMr4D","executionInfo":{"status":"ok","timestamp":1676605808520,"user_tz":300,"elapsed":954,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":["# Building and training seq2seq model"],"metadata":{"id":"RNUhD-FZMtvf"}},{"cell_type":"code","source":["#Model\n","training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","#Compiling\n","training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n","#Training\n","training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = 100, validation_split = 0.2)\n","training_model.save('training_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2QubnQ0MwfE","outputId":"105be60e-103e-4b9f-b7f2-ccb170d8c79c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/32 [========>.....................] - ETA: 36s - loss: 0.8123 - accuracy: 0.0307"]}]},{"cell_type":"markdown","source":["# Testing setup"],"metadata":{"id":"0Jod6YILMxqZ"}},{"cell_type":"code","source":["from keras.models import load_model\n","training_model = load_model('training_model.h5')\n","encoder_inputs = training_model.input[0]\n","encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n","encoder_states = [state_h_enc, state_c_enc]\n","encoder_model = Model(encoder_inputs, encoder_states)"],"metadata":{"id":"kBZvodn7M3O3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent_dim = 256\n","decoder_state_input_hidden = Input(shape=(latent_dim,))\n","decoder_state_input_cell = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]"],"metadata":{"id":"QArOQDLUM4bJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_hidden, state_cell]\n","decoder_outputs = decoder_dense(decoder_outputs)"],"metadata":{"id":"fGVdx-ryM5p6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"],"metadata":{"id":"K9Z6jNwAM68R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing our model"],"metadata":{"id":"4tvDfoiBM8PG"}},{"cell_type":"code","source":["def decode_response(test_input):\n","    #Getting the output states to pass into the decoder\n","    states_value = encoder_model.predict(test_input)\n","    #Generating empty target sequence of length 1\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    #Setting the first token of target sequence with the start token\n","    target_seq[0, 0, target_features_dict['<START>']] = 1.\n","    \n","    #A variable to store our response word by word\n","    decoded_sentence = ''\n","    \n","    stop_condition = False\n","    while not stop_condition:\n","          #Predicting output tokens with probabilities and states\n","          output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n","    #Choosing the one with highest probability\n","          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","          sampled_token = reverse_target_features_dict[sampled_token_index]\n","          decoded_sentence += \" \" + sampled_token\n","    #Stop if hit max length or found the stop token\n","          if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","    #Update the target sequence\n","          target_seq = np.zeros((1, 1, num_decoder_tokens))\n","          target_seq[0, 0, sampled_token_index] = 1.\n","          #Update states\n","          states_value = [hidden_state, cell_state]\n","    return decoded_sentence"],"metadata":{"id":"71jyFWW2NAXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ChatBot:\n","  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n","  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n","#Method to start the conversation\n","  def start_chat(self):\n","    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n","    \n","    if user_response in self.negative_responses:\n","      print(\"Ok, have a great day!\")\n","      return\n","    self.chat(user_response)\n","#Method to handle the conversation\n","  def chat(self, reply):\n","    while not self.make_exit(reply):\n","      reply = input(self.generate_response(reply)+\"\\n\")\n","    \n","  #Method to convert user input into a matrix\n","  def string_to_matrix(self, user_input):\n","    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n","    user_input_matrix = np.zeros(\n","      (1, max_encoder_seq_length, num_encoder_tokens),\n","      dtype='float32')\n","    for timestep, token in enumerate(tokens):\n","      if token in input_features_dict:\n","        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n","    return user_input_matrix\n","  \n","  #Method that will create a response using seq2seq model we built\n","  def generate_response(self, user_input):\n","    input_matrix = self.string_to_matrix(user_input)\n","    chatbot_response = decode_response(input_matrix)\n","    #Remove <START> and <END> tokens from chatbot_response\n","    chatbot_response = chatbot_response.replace(\"<START>\",'')\n","    chatbot_response = chatbot_response.replace(\"<END>\",'')\n","    return chatbot_response\n","#Method to check for exit commands\n","  def make_exit(self, reply):\n","    for exit_command in self.exit_commands:\n","      if exit_command in reply:\n","        print(\"Ok, have a great day!\")\n","        return True\n","    return False\n","  \n","chatbot = ChatBot()"],"metadata":{"id":"fE_gIk2ENEaq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chatbot.start_chat()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":621},"id":"Aj9uB08NNRDq","executionInfo":{"status":"error","timestamp":1676605672822,"user_tz":300,"elapsed":14979,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"74c45e8c-16ed-43db-81a2-14ddcc924bda"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 451ms/step\n","1/1 [==============================] - 0s 476ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n"," i you you \n","no\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-089978172fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-51-0bbfd088cbf4>\u001b[0m in \u001b[0;36mstart_chat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ok, have a great day!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#Method to handle the conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-51-0bbfd088cbf4>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, reply)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m#Method to convert user input into a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9m3pL74KUddW"},"execution_count":null,"outputs":[]}]}